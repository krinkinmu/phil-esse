\section{Освоение процесса}

Начало этого обычно связывают с появлением программно-аппаратной системы IBM-360 (ЭВМ и базовый набор ПО для этой системы). Разработка огромного по тем меркам программного проекта вскрыла многие проблемы ПИ. Менеджер проекта Фредерик Брукс в последствии написал книгу «The Mythical Man-Month: Essays on Software Engineering», основанную на полученном опыте, которая до сих пор очень популярна.

С появлением мощной и универсальной ЭВМ IBM-360 исчезла необходимость постоянного переписывания программ под новые системы (IBM-360 использовалась с 1965 по 1978 год~\cite{IBM360}). IBM-360 использовалась повсеместно, как в научных так и в бизнес приложениях.

Ключевым историческим моментом в этом периоде стали конференции НАТО по ПИ 1968 и 1969 годов, которые привлекли внимание к кризису ПО~\cite{CRISIS}. Как уже упоминалось ранее, именно с этим событием обычно связывают самое появление понятия ПИ. В чем же заключался кризис ПО?  За более чем пятнадцать лет был накоплен некоторый опыт разработки ПО. Проблема заключалась в том, что этот опыт был во многом неудачным~\footnote{Например, разработка OS/360 (операционной системы IBM-360) стоила сотни миллионов долларов, превысила сроки больше чем на год и содержала огромное количество ошибок.}. Многие проекты так и не были доведены до конца, либо были доведены до конца с превышением бюджета, сроков, или ненадлежащим качеством. С ростом мощности вычислительной техники возрастают и ожидания людей от ЭВМ, а вместе с ними и сложность программных проектов. Широкое распространение ЭВМ привело к росту спроса на новое ПО, который просто не удавалось удовлетворить~\cite{Dijkstra:1972:HP},~\cite{CRISIS}. Стала очевидной необходимость систематического подхода к разработке ПО. Разработка ПО — должна быть предсказуемой, управляемой.

Однако были примеры и удачных проектов. Например, одним из действительно значимых проектов стала операционная система UNIX. UNIX была самой маленькой, самой эффективной и самой популярной операционной системой, разработанной всего двумя людьми. Ключевой принцип простоты лег в основу того, что мы сейчас называем философией Unix~\footnote{Обычно UNIX пишут когда имеют ввиду именно оригинальную операционную систему, а Unix обозначает семейство операционных систем, использующих те же самые принципы, что и оригинальный UNIX.} и на много лет вперед определил принципы хорошего стиля программирования~\cite{Ritchie:1974:UTS},~\cite{McIlroy:1978:UTS}.

Привлечение внимания к кризису ПО стало причиной быстрого развития области. Именно на этом этапе появляются первые методологии процесса разработки ПО и первые способы измерения ПО. На этом этапе появляется и первая распространенная парадигма программирования - структурное программирование~\footnote{Структурное программирование часто называют модульным, хотя соотношение этих двух понятий не до конца ясно. Причина неясности кроется в неясности понятия модуля, сейчас под модулем понимают связанный набор сущностей программы, в то время как раньше модулями называли подпрограммы.}.

\subsection{Структурное программирование}

Структурное программирование включает три взаимосвязанные части: самоограничение программиста в используемых средствах структурирования программы, подход сверху-вниз при проектировании программы и формальное доказательство корректности программ.

\paragraph{Самоограничение} заключалось в том, что простые предложения языка программирования и составные конструкции связываются в единую программу только с помощью трех структурных конструкций: последовательное исполнение, ветвление и цикл. Все эти конструкции имеют только один вход и один выход, т. е. нельзя передать управление в середину цикла не пройдя через точку входа в цикл, и нельзя выйти из цикла не пройдя точку выхода. Языки программирования того времени~\footnote{И современные языки тоже.} предоставляли и другие конструкции управления потоком исполнения программы, в частности, печально известную GOTO. Именно на нее и направили свою критику представители структурного программирования~\cite{Dijkstra:1968:LEG}. Такая критика не была воспринята однозначно. Дональд Кнут написал статью, в которой выделил несколько задач, в которых GOTO является оптимальной конструкцией~\cite{Knuth:1974:SPG}. Но, в целом программисты пришли к согласию, что конструкцию GOTO легко использовать неправильно.

Изначально совсем не очевидно, что такое ограничение не сократит множества возможных программ. Однако структурное программирование имело строгие математические основания, одним из которых была структурная теорема~\cite{SPT}, доказанная Бёмом и Якопини. Суть теоремы как раз и заключалась в том, что фактически любую программу можно написать с помощью трех указанных конструкций.

Пожалуй, это первый известный мне пример самоограничения в программировании, когда инженер намеренно отказывается от использования некоторых возможностей в пользу понятности программы. До этого программисты пытались "выжать все" из ЭВМ, поэтому старались использовать все ее возможности. А программы были наполнены множеством нетривиальных трюков и уловок нацеленных на большую эффективность.

\paragraph{Проектирование больших программ} стало еще одной проблемой, которую было призвано решить структурное программирование. Дейкстра отмечает, что одной из причин кризиса ПО стал рост мощности ЭВМ~\cite{Dijkstra:1972:HP}. Который в свою очередь привел к росту ожиданий пользователей от ЭВМ. Люди начинают применять ЭВМ во все более сложных задачах и ПО, по необходимости, тоже становится сложнее. Подход "Code and Fix" более не пригоден для разработки, и структурное программирование предлагает первое решение - проектирование сверху-вниз. Суть подхода заключается в последовательном разделении большой задачи на подзадачи, которые в свою очередь разделяются на еще более маленькие подзадачи и так до тех пор, пока мы не придем к задаче, которую легко можно решить на ЭВМ. После чего идет обратный процесс - полученные решения простых задач объединяются в решения более сложных и так далее.

Сейчас можно сказать, что в подходе нет ничего революционного, мы бы могли назвать его очевидным. Но в то время, когда не было никакого систематического подхода к разработке ПО, он стал важным шагом и привлек внимание к проблеме. Кроме того стоит отметить, что пропагандисты структурного программирования успешно демонстрировали применение этого подхода на практике. Причем как на простых примерах~\cite{Wirth:1971:PDS}, так и на реальных проектах. Например, известный проект по созданию системы индексации для New York Time выполненный Харланом Милсом. Сложность проекта была оценена в 30 человеко-лет, но Милс закончил его самостоятельно за 6 месяцев~\cite{Aron:1979:SP}. В связи с чем структурное программирование приобрело определенную популярность.

\paragraph{Корректность программ} стала еще одной важной проблемой, которую должно было решить структурное программирование. Действительно, человек доверят компьютеру решение задач, с которыми он не может справится самостоятельно. Но программы для ЭВМ создаются людьми, а они неизбежно ошибаются. Как можно доверять результату работы программы, если нет никаких способов проверить правильность этого результата?

История программирования знает много примеров, когда программные ошибки приводили к большим финансовым потерям или даже стоили жизни людей. Примеры таких ошибок можно найти в работе~\cite{Zhivich:2009:RCSE}. И в связи с все большим распространением компьютеризированных технологий вопрос становится все острее.

Корректности программ и до появления структурного программирования уделялось некоторое внимание~\footnote{Его нельзя назвать систематичным подходом.}. Основным инструментом проверки корректности программ было~\footnote{И остается на сегодняшний день.} тестирование. Т. е. результат работы программы сравнивается с известными правильными результатами на некотором ограниченном наборе тестов. Более того на этом этапе начинается разработка систематических подходов к тестированию, например,~\cite{Myers:1979:AST}.

Критический недостаток тестирования как средства проверки ПО заключается в том, что он дает некоторый уровень уверенности в правильности программы, но не дает гарантий корректности. Даже небольшие программы имеют огромное количество внутренних состояний и возможных путей исполнения. Протестировать все пути исполнения нет никакой физической возможности~\footnote{Их число измеряется астрономическими величинами, запустить тест для каждого варианта просто не хватит времени.}. Более того, в этом нет никакого смысла — если бы были известны правильные результаты работы программы на всех входных данных, то сама программа была бы не нужна. Тестирование может показать наличие ошибок в ПО, но никогда не сможет доказать их отсутствие~\cite{Dijkstra:1972:CIN}~\footnote{Однако в некоторых ситуациях инженеры готовы примериться с возможным наличием ошибок в ПО.}.

В рамках структурного программирования развивался альтернативный формальный подход к корректности программ. Т. е. правильность программы доказывалась строгими математическими методами. Структурное программирование ввело в ПИ такие понятия как предусловие, постусловие и инвариант. Предусловие - это формальное логическое утверждение, которое выполняется перед началом некоторого участка программы. Постусловие - это формальное логическое утверждение, которое истинно по завершению участка программы, если предусловие было истинно. Инвариант - это формальное логическое утверждение, которое должно быть истинно перед и по окончанию каждой итерации цикла, т. е. оно совмещает понятия предусловия и постусловия для циклов. Доказательство корректности программы выполняется следующим образом:
\begin{enumerate}
  \item формулируется предусловие, которое описывает ограничения и взаимосвязь входных данных;
  \item из предусловия последовательно для каждой структурной единицы участка программы выводится постусловие, которое становится предусловием для следующей структурной единицы, и так до тех пор пока мы не получим постусловие для всего участка программы;
  \item если из постусловия участка программы логически следует правильность результата, то корректность программы доказана.
\end{enumerate}

Математические основания такого способа доказательства корректности была заложены в работе Чарльза Хоара~\cite{Hoare:1969:ABC}, а в работе~\cite{Dijkstra:1972:CIN} Дейкстра развивает подход и описывает несколько паттерном или приемов, которые могут оказаться полезными при таком доказательстве корректности программ~\footnote{В частности он демонстрирует использование математической индукции применительно к циклам, и описывает паттерн "перечисления".}.

Такое формальное доказательство не получило широко распространения в индустрии, потому что этот подход не подлежал автоматизации и плохо масштабировался на большие программы. Фактически доказательство корректности программ было похоже на доказательство математической теоремы. Кроме того представители структурного программирования не предлагали каких-то формальных механических методов для формулировки предусловий и инвариантов. Однако этот подход стал первым формальным методом.

\subsection{Метрология ПО}

Как уже отмечалось ПО нельзя измерить обычными средствами. Программа не имеет массы, заряда или температуры. Однако, чтобы оценивать сложность и стоимость программ необходим какой-то способ оценки. Измерить ПО пытались и раньше, но в этом этапе вышли две действительно заметные работы. Первая~\cite{McCabe:1976:CM} применяет методы теории графов для оценки сложности программ и вводит понятие цикломатической сложности. Т. е. при оценке сложности используется граф потока управления программы, безотносительно смыслового наполнения. Интересно, что такая оценка сложности программы может быть автоматизирована и, соответственно, может служить формальным критерием оценки качества кода даже в больших проектах. Ее можно использовать как формальный критерий декомпозиции.

Другая работа~\cite{Halstead:1977:ESS} рассматривает программу как набор слов, каждое из которых можно считать либо оператором либо операндом. Всем метрики Холстеда это рассчитываются как функции от количества операторов и операндов. Метрики Холстеда определяют такие базовые понятия как длина программы и словарь программы. Далее на основе базовых понятий определяются такие понятия как объем программы - метрика для оценки сложности реализуемого алгоритма, эта метрика определяет психическую сложность~\footnote{Какое количество умственных операций необходимо произвести, чтобы разработать программу.}. Потенциальный (минимальный) объем - объем реализации минимального размера. Также в работе определяются такие метрики как уровень, сложность и интеллектуальное наполнение программы. На их основе оценивается количество усилий программиста, необходимых для реализации программы и количество времени. И все эти метрики оцениваются исключительно формальными методами.

Метрики Холстеда были подвергнуты определенной критике. Критику этих метрик можно разделить на две группы. Первая группа критикует слабость теоретических оснований метрик Холстеда и обоснованность используемых математических выражений~\footnote{Действительно, как можно математически выразить интеллектуальное наполнение программы?}. Кроме того далеко не любое слово в языках программирования можно однозначно отнести либо к операторам либо к операндам. Вторая группа критикует эмпирическую проверку теории Холстеда. Критика эмпирических результатов в основном заключалась в критике тестовой выборки программ.

Более того, отмечу, что программисту не трудно написать программу так, чтобы по метрикам Холстеда ее можно было считать качественной, хотя по мнению экспертов она таковой считаться не будет.

Как бы то ни было, метрики Холстеда имеют под собой некоторые интуитивные основания~\footnote{Например, они показывают объем дублирования в программе, а дублирование считается одним из признаков плохого кода.} и их эмпирическая проверка показала довольно интересные результаты. Как и цикломатическая сложность программы, метрики Холстеда могут быть подсчитаны автоматически, а значит могут указать на проблемные места большого программного проекта. Поэтому разработку формальных методов для оценки программ стоит считать важным шагом в истории ПИ.

\subsection{Каскадная модель разработки ПО}

Модель или методология разработки ПО выделяет фазы процесса разработки, определяет взаимные переходы между этими фазами, а также результаты каждой из фаз. Т. е. в отличие от парадигм, которые касаются дизайна программы и кодирования, методологии уделяют внимание организации процесса разработки ПО.

Выделение первых методологий также связано с кризисом ПО. Первые появившиеся модели разработки ПО уделяют особое внимание фазе сбора и анализа требований. Т. е. фактически фазе постановки задачи. Первые методологии предполагают, что все требования будут собраны, формализованы и систематизированы перед началом непосредственной разработки, и на основании этих данных можно жестко спланировать весь дальнейший процесс~\footnote{Поэтому первые методология называют жесткими - планирование всего процесса разработки в самом начале.}.

Появление именно жестких методологий в самом начале можно объяснить тем, что компьютеры могли себе позволить только довольно большие компании и государственные структуры с высоким уровнем бюрократии. Поэтому такой жесткий подход к планированию процесса оказался самым приемлемым~\footnote{И до сих пор большие компании часто предпочитают жесткие методологии для разработки больших коммерческих проектов.}.

Первой формально описанной методологией стала каскадная модель~\footnote{В англоязычной литературе используется термин "waterfall", потому что графическая схема изображающая эту модель разработки напоминает водопад.}~\cite{Royce:1970:MDL}. В работе Ройс описывает идеализированный процесс разработки как начальную точку. Затем последовательно излагает проблемы, к которым может привести такой процесс и дополняет модель. Основанная идея методологии заключается в том, что процесс разработки распадается на несколько фаз: сбор требований, предварительный дизайн, анализ, дизайн программы, кодирование, тестирование, сопровождение. Фазы идут последовательно одна за другой.

К ключевыми моментами методологии описанной Ройсом можно отнести следующие пункты:
\begin{itemize}
  \item предварительный дизайн идет перед анализом, это необходимо чтобы как можно раньше вскрыть технические риски, а предварительный дизайн позволяет получить информацию необходимую для оценки этих рисков~\footnote{Проще говоря, чтобы понять с какими проблемами можно столкнуться нужно попробовать решить задачу.};
  \item важность документации, документировать нужно все от требований до дизайна, все принятые решения должны быть зафиксированы;
  \item делайте дважды, этот пункт говорит о том, что фаза предварительного дизайна должна быть дублировать весь процесс разработки в миниатюре, по факту этот пункт является дополнением к первому;
  \item планируйте, управляйте и отслеживайте тестирование, Ройс отмечает, что тестирование - фаза потребляющая больше всех ресурсов, поэтому важно контролировать этот процесс как можно строже;
  \item вовлекайте заказчика в процесс, Ройс отмечает, что в силу специфики ПИ, даже после согласования требований с заказчиком остается очень много простора для их интерпретации~\footnote{Вероятно, потому что многие требования трудно выразить формально, например, как выразить формально "интуитивный интерфейс", но заказчики всегда хотят иметь такой.}.
\end{itemize}

Оригинальная каскадная модель со временем получила множество развитий и вариаций, устраняющих различные слабости оригинальной модели или учитывающих специфику конкретной организации разрабатывающей ПО~\footnote{Примерами таких расширений могу служить модель "сашими" или "V-модель".}. Основная слабость этой модели заключалась в отсутствии итеративности. Очень трудно точно зафиксировать все требования к ПО с самого начала проекта и учесть все возможные риски не попробовав решить задачу. Однако каскадная модель предполагала последовательное прохождение всех фаз, с очень ограниченной возможностью для возврата к предыдущим фазам.

Не смотря на недостатки, различные вариации каскадной модели до сих пор используются, и заслуга выделения основных фаз процесса разработки ПО и результатов этих фаз принадлежит каскадной модели. Она является отправной точкой развития методологий разработки ПО, фактически последующие методологии разрабатывались как результат осознания проблем возникающих при использовании классической модели.
