\section{Этап стабилизации}

Начало этапа стабилизации обычно связывают с появлением программно-аппаратной системы IBM-360 (ЭВМ и базовый набор ПО для этой системы). Разработка огромного по тем меркам программного проекта вскрыла многие проблемы ПИ. Менеджер проекта Фредерик Брукс в последствии написал книгу «The Mythical Man-Month: Essays on Software 
Engineering», основанную на полученном опыте, которая до сих пор очень популярна.

С появлением мощной и универсальной ЭВМ IBM-360 исчезла необходимость постоянного переписывания программ под новые системы (IBM-360 использовалась с 1965 по 1978 год~\cite{IBM360}). IBM-360 использовалась повсеместно, как в научных так и в бизнес приложениях.

Ключевым историческим моментом в этом периоде стали конференции НАТО по ПИ 1968 и 1969 годов, которые привлекли внимание к кризису ПО~\cite{CRISIS}. Как уже упоминалось ранее, именно с этим событием обычно связывают самое появление понятия ПИ. В чем же заключался кризис ПО?  За более чем пятнадцать лет был накоплен некоторый опыт разработки ПО. Проблема заключалась в том, что этот опыт был во многом неудачным. Многие проекты так и не были доведены до конца, либо были доведены до конца с превышением бюджета, сроков, или ненадлежащим качеством. С ростом мощности вычислительной техники возрастали ожидания людей от ЭВМ, а вместе с ними и сложность программных проектов. Широкое распространение ЭВМ привело к росту спроса на новое ПО, который просто не удавалось удовлетворить~\cite{Dijkstra:1972:HP},~\cite{CRISIS}. Стала очевидной необходимость систематического подхода к разработке ПО. Разработка ПО — должна быть предсказуемой, управляемой.

Методологические разработки этого задают ориентацию на создание больших программных систем. Они начинают уделять внимание фазам процесса разработки ПО, особенно фазе сбора и анализа требований, т. е. фазе постановки задачи (~\cite{Alford:1976:REM},~\cite{Ross:1977:SA}). Другая часть разработок направлена непосредственно на организацию структуры программы и доказательство ее корректности. В этой области выделяется разработка парадигмы структурного программирования с ее строгими математическими основаниями и формальным подходом к проверке корректности программ.

\subsection{Проблема корректности программ}

Корректности программ и до появления структурного программирования уделялось некоторое внимание. Основным инструментом проверки корректности программ был и остается тестирование. Т. е. результат работы программы сравнивается с известным правильным результатом на некотором ограниченном наборе тестов. Важность тестирования в последнее время только возрастает. Во основном в связи с тем, что чем раньше будет найдена проблема в ПО, тем меньше будет стоимость ее устранения. В работе [18] приведены примеры финансовых потерь из-за программных ошибок, сделан обзор методологий тестирования и разработана математическая модель стоимости программных ошибок. Стоит отметить, что ошибки в ПО могут приводить не только к финансовым потерям, но иногда могут стоить и жизни людей.

Критический недостаток тестирования как средства проверки ПО заключается в том, что он дает некоторый уровень уверенности в правильности программы, но не дает гарантий корректности программ. Даже небольшие программы имеют огромное количество внутренних состояний и возможных путей исполнения. Протестировать все пути исполнения нет никакой физической возможности (их число измеряется астрономическими величинами). Более того, в этом нет никакого смысла — если бы были известны правильные результаты работы программы на всех входных данных, то сама программа была бы не нужна. Тестирование может показать наличие ошибок в ПО, но никогда не сможет доказать их отсутствие~\cite{Dijkstra:1972:CIN}. Однако в некоторых ситуациях инженеры готовы примериться с возможным наличием ошибок в ПО.

\subsection{Структурное программирование}

Структурное программирование (разрабатывалось такими учеными как Эдсгер Дейкстра и Чарльз Хоар) стало первым шагом в разработке методологического подхода к конструированию больших и надежных программ~\cite{Grier}. Подход предлагает использование иерархической декомпозиции как способ проектирования ПО (подход сверху-вниз), и применение формальной логики как способ доказательства корректности программы.

Иерархическая декомпозиция заключается в декомпозиции задачи на части. Каждая часть в свою очередь сам разделяется на части, и так далее, до тех пор пока мы не придем к задаче, которую можем решить. Потом начинается обратный процесс, из блоков решающих простые задачи, собираются блоки решающие более сложные задачи и так далее. На таком уровне подход не выглядит слишком новаторским, однако в дополнение к этой общей идее на каждый блок, решающий некоторую задачу налагается структурное ограничение. 

Каждый блок имеет ровно один вход — точку входа, и ровно один выход — точку выхода. Нельзя передать управление в середину блока, не пройдя точку входа, и нельзя передать управление за пределы блока не пройдя точку выхода.

Изначально, совершенно не очевидно, что такое структурное ограничение на программы не ограничивает множество возможных программ. Однако в 1966 году Бём и Якопини доказали теорему~\cite{SPT}, которая гарантировала, что фактически любая программа может быть написана с использованием всего трех структурных конструкций, которые позволяют компоновать блоки в более крупные блоки не нарушая структурного ограничения. Эта теорема не предназначалась для обоснования структурного программирования (строго говоря оно появилось несколько позже), ведь техники используемые в статье скорее запутывали программу, чем делали ее более понятной. Однако она стала формальным обоснованием того, что такое структурное ограничение не сокращает множества программ, которые можно реализовать.

Дейкстра разрабатывает подход структурного программирования в работе «Notes on Structured Programming»~\cite{Dijkstra:1972:CIN}. Он акцентирует внимание на том, что возможности человека очень ограничены — он не способен обрабатывать такое количество информации, с которой без проблем справляется компьютер. И действительно, в противном случае нам бы не понадобились ЭВМ. Но с другой стороны, если ЭВМ обрабатывает такие объемы данных, с которыми не справляется человек, то как мы можем доверять этим результатам, ведь проверить их, зачастую, нет никакой возможности. Причем с ростом мощности ЭВМ и сложности ПО ситуация становится только хуже. В связи с этим возрастает роль систематических подходов к разработке ПО, с целью минимизировать возможность ошибки, а также средств строго формального доказательства корректности программ.

Основы формального доказательства корректности программ заложила работа~\cite{Hoare:1969:ABC}, где Хоар формулирует набор аксиом и набор правил вывода, т. е. предлагает строгий математический аппарат. В работе~\cite{Dijkstra:1972:CIN} Дейкстра рассматривает более широкий круг тем, и идет несколько дальше описывая паттерны рассуждения, которые будут полезны при разработке программ и доказательстве ее корректности, т. е. работа носит более инженерный характер.

Первый из паттернов условно называется «перечисление». Рассмотрим применение этого паттерна на простом примере. Пусть у нас есть следующий простой участок программы:
\begin{lstlisting}
dd = dd / 2;
if (dd <= r)
	r := r - dd;
\end{lstlisting}

Первая строка делит значение dd на два, вторая строка сравнивает значение dd со значением r, и если первое меньше или равно второму, то уменьшает значение r на значение dd.

Мы хотим формально доказать, что эта последовательность из двух действий сохраняет истинность выражения $0 \le r < dd$. Т. е. если выражение было истинно до выполнения этих действий, то оно будет истинно и после выполнения этих действий. Очевидно, что после выполнения первого действия мы можем гарантировать истинность выражения $0 \le r < 2 dd$. Обратите внимание, что после выполнения первого действия изменилось значение dd, в математике для новых значений, обычно, вводя новые обозначения, но в программировании так сделать не получится.

Перед выполнением второго действия у нас есть две возможности:
\begin{enumerate}
  \item $dd \le r$, вместе с $0 \le r < 2 dd$. Из этого можно заключить, что $dd \le r < 2 dd$. Так как выражение $dd \le r$ истинно, то значение r будет уменьшено на значение dd. С учетом всех выкладок выше, после этого действия получаем, что истинно выражение $0 \le r < dd$, просто по свойствам арифметики.
  \item $dd > r$, вместе с $0 \le r < 2 dd$. В этом случае выражение $dd \le r$ — ложно, и, соответственно, уменьшение r не будет выполнено. На выходе, совместив два условия вместе получаем, что $0 \le r < dd$.
\end{enumerate}

Таким образом мы рассмотрели два варианта, которые покрывают все возможности. Действительно, либо выражение $dd \le r$ — истинно, либо $dd > r$ — истинно, они не могут быть одновременно ложны. И в обоих случаях мы доказали корректность утверждения. В этом и заключается метод перечисления — мы перечисляем все возможные варианты.

Второй паттерн рассуждения, или метод рассуждения, важность которого подчеркивает Дейкстра — метод математической индукции. Метод математической индукции чрезвычайно важен для математики и заслуживает отдельной работы (и такие работы есть, например, работа~\cite{Shen} целиком посвящена объяснению метода математической индукции, целевая аудитория — школьники 7-11 классов, а работа~\cite{Bussey:1917:IND} посвящена исключительно истории метода). Я не буду демонстрировать пример математической индукции для доказательства корректности программ в этой работе, интересующиеся могут обратиться к работе~\cite{Dijkstra:1972:CIN}. Ограничимся более простым и компактным примером, с целью продемонстрировать, в чем именно заключается метод математической индукции.

Математическая индукция обязательно включает базу индукции, индуктивное предположение и индуктивный переход. База индукции — это доказательство математического утверждения для некоторого простого частного случая, обычно утверждение проверяется непосредственно. Например, мы хотим показать справедливость математической формулы: $\sum_{i=1}^{n} i = {n \left( n + 1\right)\over 2}$. В качестве базы индукции проверим ее справедливость для n равного 1 — непосредственная подстановка единицы в формулу дает нам равенство.
	Индуктивное предположение заключается в том, что мы предполагаем, что выражение справедливо для некоторого n, и, возможно, для всех меньших значений. Индуктивный переход заключается в том, чтобы доказать справедливость утверждения для n + 1 основываясь на индуктивном предположении. Для формулы выше, простые математические выкладки дают такое доказательство:
\[
	\sum_{i = 1}^{n + 1} i = n + 1 + \sum_{i = 1}^{n} i = n + 1 + {n\left( n + 1\right)\over 2} = {\left( n + 1\right) \left( n + 2\right)\over 2}
\]
Из базы индукции и индуктивного перехода следует истинность утверждения для любого целого $n \ge 1$. Математическая индукции — это рабочая лошадь дискретной математики, однако пользоваться ей стоит аккуратно, примеры индуктивных доказательств абсурдных утверждений вы можете найти в~\cite{Shen}.

Чтобы доказать корректность программы, из предусловия — утверждения, которое верно перед началом программы, используя математический аппарат и описанные выше паттерн перечисления и метод математической индукции (и не только) мы выводим постусловие — утверждение, которое истинно по завершении программы. И если ожидаемый результат работы программы следует из постусловия, то программа корректна. Доказывать корректность сразу всей программы не обязательно, мы можем отдельно доказывать корректность ее частей, а потом компоновать предусловия и полученные постусловия, для доказательства корректности всей программы. Комбинировать доказательства корректности различных частей программы как раз и позволяет структурное ограничение на блоки, упомянутое выше.

В качестве заключения, стоит отметить, что формальная верификация программ в том виде, который предлагал подход структурного программирования не получила большого распространения. Доказательство корректности программ мало чем отличалось от доказательства теорем математики или корректности алгоритмов. Такой подход не подлежал автоматизации, и поэтому отнимал много ресурсов, а значит не всегда был оправдан. Его демонстрировали на небольших примерах, но он плохо масштабировался на большие программные проекты того времени и не удовлетворял нуждам промышленности. Но подходы структурного программирования к дизайну программ стал общепринятым~\cite{Floyd:1979:PP}.

\subsection{Водопад}

Методология выделяет фазы процесса разработки ПО, определяет взаимные переходы между этими фазами, а также результаты выполнения каждой из фаз. «Водопад» — стал первой формально описанной методологией организации процесса разработки ПО~\cite{Royce:1987:MDL}. В этой методологии выделяются следующие фазы: анализом и спецификация требований, дизайн программы, реализация или кодирование, тестирование, развертывание и поддержка. Фазы процесса идут ровно в таком порядке, возможно, в случае обнаружения ошибок происходит возврат на один шаг назад.

Сейчас «водопад» относят к так называемым жестким методологиям. Это значит, что в методологии особенно важны первые этапы связанные с анализом и спецификацией требований, они занимают самую большую часть времени процесса разработки. Фактически этот этап определяет план всей дальнейшей работы. После фиксации требований и разработки дизайна программы вернуться назад к анализу требований довольно проблематично — фактически это означает начать работу заново. Именно поэтому «водопад» называют жесткой методологией, в противовес гибким методологиям. В целом эта методология следует тенденциям того времени. После осознания необходимости правильной организации процесса разработки ПО, первое что привлекло внимание — фаза постановки задачи и планирования.

В ответ на недостатки «водопада» появилось несколько различных его модификаций, например, «сашими» - в отличие от «водопада», фазы не следуют строго друг за другом, а частично перекрываются во времени. На данный момент, «водопад» и его развития несколько уступили позиции гибким итеративным методологиям, но все еще используются в крупных компаниях, для которых в первую очередь важна предсказуемость процесса разработки.

\subsection{UNIX}

Говоря об этапе стабилизации нельзя обойти стороной такую значительную разработку как UNIX. Многие технологии появились вместе с и благодаря UNIX. Начиная от специфичных средств разработки ПО в их современном виде — текстовые редакторы и отладчики, заканчивая такими глобальными технологиями как Интернет.

UNIX — многопользовательская, интерактивная операционная система, предок современных операционных систем. Первая версия была разработана в 1969 году Денисом Ритичи и Кеном Томпсоном~\cite{Ritchie:1974:UTS}. Основным достижением UNIX, по мнению создателей, является ее простота. Они показали, что мощная операционная система не обязана быть сложной или очень дорогой (имеется ввиду стоимость разработки, разработка UNIX заняла меньше чем два человека-года).

Операционной системе UNIX программная инженерия в первую очередь обязана за «философию Unix». Философия Unix включает в себя ряд принципов, которыми стоит руководствоваться при проектирование ПО. Дуглас Макилрой формулирует принципы философии Unix следующим образом~\cite{McIlroy:1978:UTS}:
\begin{itemize}
  \item каждая программа должна делать одну вещь, но делать ее хорошо; для новой задачи реализуйте новую программу, а не усложняйте уже существующую новыми возможностями;
  \item рассчитывайте на то, что вывод программы, станет входом для другой программы, возможно еще не известной; не засоряйте вывод программы лишней информацией; избегайте бинарных форматов; не настаивайте на интерактивном вводе;
  \item проектируйте и реализуйте программное обеспечение так, чтобы его можно было попробовать как можно раньше; не бойтесь выкидывать неуклюжие части и переписывать их заново;
  \item предпочитайте программные утилиты человеческому труду, чтобы облегчить задачи разработки ПО.
\end{itemize}

Не все эти принципы можно трактовать однозначно положительно, в частности часть третьего пункта про выкидывание частей программы требует аккуратности, как показывает опыт ПИ. Но основные концепции — стремление к простоте, модульность, быстрое прототипирование и автоматизация, на много лет вперед определели содержание «хорошего стиля» программирования.
